title: caffe
date: 2015-9-8 21:50:24
tags: caffe

---

[softmax](http://www.cnblogs.com/tornadomeet/archive/2013/03/22/2975978.html) 是logistic回归的多值的扩展。

* **forward and backward**
![Imgur](http://wangfan.net:9000/DrIjXL7.png)

 >The Net::Forward() and Net::Backward() methods carry out the respective passes while Layer::Forward() and Layer::Backward() compute each step.
 >The Solver optimizes a model by first calling forward to yield the output and loss, then calling backward to generate the gradient of the model, and then incorporating the gradient into a weight update that attempts to minimize the loss. 

<!--more-->

* **layer**
```
acoud
```