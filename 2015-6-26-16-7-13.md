title: cuda c 第三章
date: 2015-6-26 16:7:13
tags: 
---
* #####定义
	* CPU以及系统的内存称为主机。
	* GPU及其内存称为设备
	* 核函数为在设备上运行的函数，使用`__global__`修饰 

* #####内存分配与释放
```c
int c;
int * dev_c;
cudaMalloc((void**)&dev_c,sizeof(int));
cudaFree(dev_c);
```
<!--more-->

* #####内存拷贝
```c
int c;
int * dev_c;
cudaMemcpy(&c,dev_c,sizeof(int),cudaMemcpyDeviceToHost);
\\cudaMemcpyDeviceToHost
\\cudaMemcpyHostToDevice
\\cudaMemcpyDeviceToDevice
```

* #####获取设备数量和属性
```c
int count;
cudaDeviceProp prop;
cudaGetDeviceCount(&count);
cudaGetDeviceProperties(&prop,0);
```
![prop](http://i.imgur.com/D8cxk9n.png)

* #####并行编程
```c
__global__ void add( int *a, int *b, int *c ) {
    int tid = blockIdx.x;    // this thread handles the data at its thread id
    if (tid < N)
        c[tid] = a[tid] + b[tid];
}
```
**注意** `__global__`和`__device__`函数的区别是：前者说明是由主机调用的在GPU上执行的函数，而后者只能由在GPU上的函数调用，即只能由其他`__global__`和`__device__`的函数调用。
* #####函数调用
```c
kernel<<<m,n>>>()
```
其中，m指使用的并行线程块的数量，这个线程块集合成为一个gird。blockIdx.x当前位于哪一个线程块。cuda支持二维并行线程块数组。当使用二维的grid时，使用dim3类型设置。如：
```c
dim3 grid(DIM,DIM);
kernel<<<grid,1>>>();
```
此时得到当前block的id涉及
```c
int x = blockIdx.x;
int y = blockIdx.y;
int offset = x + y*gridDim.x;
```
